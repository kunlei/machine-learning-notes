[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Notes",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "My journey of learning Machine Learning (ML).\n\nAn Introduction to Statistical Learning: with Applications in Python\nIntroduction to Machine Learning with Python: A Guide for Data Scientists",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "2  Environment Setup",
    "section": "",
    "text": "2.1 conda\nInstall conda from here:\nhttps://conda.io/projects/conda/en/latest/user-guide/install/macos.html",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#conda",
    "href": "setup.html#conda",
    "title": "2  Environment Setup",
    "section": "",
    "text": "# to list all available environments\nconda env list\n\n# to remove an environment\nconda env remove -n 'env_name'",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#machine-learning-packages",
    "href": "setup.html#machine-learning-packages",
    "title": "2  Environment Setup",
    "section": "2.2 Machine learning packages",
    "text": "2.2 Machine learning packages\nFirst install some of the essential libraries and tools\nconda install numpy scipy pandas matplotlib seaborn plotly ipython scikit-learn jupyterlab ipykernel pyarrow",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#add-conda-environment-into-notebook-kernel",
    "href": "setup.html#add-conda-environment-into-notebook-kernel",
    "title": "2  Environment Setup",
    "section": "2.3 Add conda environment into notebook kernel",
    "text": "2.3 Add conda environment into notebook kernel\n## Create the virtual environment\nconda create -n 'environment_name'\n\n## Activate the virtual environment\nconda activate 'environment_name'\n\n## Make sure that ipykernel is installed\npip install --user ipykernel\n\n## Add the new virtual environment to Jupyter\npython -m ipykernel install --user --name='environment_name'\n\n## To list existing Jupyter virtual environments\njupyter kernelspec list\n\n## To remove the environment from Jupyter\njupyter kernelspec uninstall 'environment_name'\n\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport scipy as sp\nimport IPython\nimport sklearn\nimport seaborn as sns\nimport plotly\n\nprint(f'Python version: {sys.version}')\nprint(f'numpy version: {np.__version__}')\nprint(f'pandas version: {pd.__version__}')\nprint(f'matplotlib version: {matplotlib.__version__}')\nprint(f'scipy version: {sp.__version__}')\nprint(f'IPython version: {IPython.__version__}')\nprint(f'sklearn version: {sklearn.__version__}')\nprint(f'seaborn version: {sns.__version__}')\nprint(f'plotly version: {plotly.__version__}')\n\nPython version: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:41:52) [Clang 15.0.7 ]\nnumpy version: 1.26.2\npandas version: 2.1.4\nmatplotlib version: 3.7.2\nscipy version: 1.11.2\nIPython version: 8.15.0\nsklearn version: 1.3.2\nseaborn version: 0.13.1\nplotly version: 5.18.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "explore-iris.html",
    "href": "explore-iris.html",
    "title": "3  Explore Iris Classification",
    "section": "",
    "text": "3.1 Classification\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], random_state=0)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((112, 4), (38, 4), (112,), (38,))\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\n\nKNeighborsClassifier(n_neighbors=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier(n_neighbors=1)\ny_pred = knn.predict(X_test)\nknn.score(X_test, y_test)\n\n0.9736842105263158",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Explore Iris Classification</span>"
    ]
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "4  Datasets",
    "section": "",
    "text": "4.1 The Wisconsin Breast Cancer dataset\nfrom sklearn.datasets import load_breast_cancer\nimport pandas as pd\n\ncancer = load_breast_cancer()\ndf_cancer = pd.DataFrame(data=cancer['data'], columns=cancer['feature_names'])\ndf_cancer['target'] = cancer['target']\ndf_cancer\n\n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\ntarget\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.30010\n0.14710\n0.2419\n0.07871\n...\n17.33\n184.60\n2019.0\n0.16220\n0.66560\n0.7119\n0.2654\n0.4601\n0.11890\n0\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.08690\n0.07017\n0.1812\n0.05667\n...\n23.41\n158.80\n1956.0\n0.12380\n0.18660\n0.2416\n0.1860\n0.2750\n0.08902\n0\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.19740\n0.12790\n0.2069\n0.05999\n...\n25.53\n152.50\n1709.0\n0.14440\n0.42450\n0.4504\n0.2430\n0.3613\n0.08758\n0\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.24140\n0.10520\n0.2597\n0.09744\n...\n26.50\n98.87\n567.7\n0.20980\n0.86630\n0.6869\n0.2575\n0.6638\n0.17300\n0\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.19800\n0.10430\n0.1809\n0.05883\n...\n16.67\n152.20\n1575.0\n0.13740\n0.20500\n0.4000\n0.1625\n0.2364\n0.07678\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n564\n21.56\n22.39\n142.00\n1479.0\n0.11100\n0.11590\n0.24390\n0.13890\n0.1726\n0.05623\n...\n26.40\n166.10\n2027.0\n0.14100\n0.21130\n0.4107\n0.2216\n0.2060\n0.07115\n0\n\n\n565\n20.13\n28.25\n131.20\n1261.0\n0.09780\n0.10340\n0.14400\n0.09791\n0.1752\n0.05533\n...\n38.25\n155.00\n1731.0\n0.11660\n0.19220\n0.3215\n0.1628\n0.2572\n0.06637\n0\n\n\n566\n16.60\n28.08\n108.30\n858.1\n0.08455\n0.10230\n0.09251\n0.05302\n0.1590\n0.05648\n...\n34.12\n126.70\n1124.0\n0.11390\n0.30940\n0.3403\n0.1418\n0.2218\n0.07820\n0\n\n\n567\n20.60\n29.33\n140.10\n1265.0\n0.11780\n0.27700\n0.35140\n0.15200\n0.2397\n0.07016\n...\n39.42\n184.60\n1821.0\n0.16500\n0.86810\n0.9387\n0.2650\n0.4087\n0.12400\n0\n\n\n568\n7.76\n24.54\n47.92\n181.0\n0.05263\n0.04362\n0.00000\n0.00000\n0.1587\n0.05884\n...\n30.37\n59.16\n268.6\n0.08996\n0.06444\n0.0000\n0.0000\n0.2871\n0.07039\n1\n\n\n\n\n569 rows × 31 columns",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "datasets.html#the-diabetes-dataset",
    "href": "datasets.html#the-diabetes-dataset",
    "title": "4  Datasets",
    "section": "4.2 The Diabetes Dataset",
    "text": "4.2 The Diabetes Dataset\n\nfrom sklearn.datasets import load_diabetes\n\ndiabetes = load_diabetes()\n\n\ndf_diabetes = pd.DataFrame(data=diabetes['data'], columns=diabetes['feature_names'])\ndf_diabetes['target'] = diabetes['target']\n\n\ndf_diabetes\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\ntarget\n\n\n\n\n0\n0.038076\n0.050680\n0.061696\n0.021872\n-0.044223\n-0.034821\n-0.043401\n-0.002592\n0.019907\n-0.017646\n151.0\n\n\n1\n-0.001882\n-0.044642\n-0.051474\n-0.026328\n-0.008449\n-0.019163\n0.074412\n-0.039493\n-0.068332\n-0.092204\n75.0\n\n\n2\n0.085299\n0.050680\n0.044451\n-0.005670\n-0.045599\n-0.034194\n-0.032356\n-0.002592\n0.002861\n-0.025930\n141.0\n\n\n3\n-0.089063\n-0.044642\n-0.011595\n-0.036656\n0.012191\n0.024991\n-0.036038\n0.034309\n0.022688\n-0.009362\n206.0\n\n\n4\n0.005383\n-0.044642\n-0.036385\n0.021872\n0.003935\n0.015596\n0.008142\n-0.002592\n-0.031988\n-0.046641\n135.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n437\n0.041708\n0.050680\n0.019662\n0.059744\n-0.005697\n-0.002566\n-0.028674\n-0.002592\n0.031193\n0.007207\n178.0\n\n\n438\n-0.005515\n0.050680\n-0.015906\n-0.067642\n0.049341\n0.079165\n-0.028674\n0.034309\n-0.018114\n0.044485\n104.0\n\n\n439\n0.041708\n0.050680\n-0.015906\n0.017293\n-0.037344\n-0.013840\n-0.024993\n-0.011080\n-0.046883\n0.015491\n132.0\n\n\n440\n-0.045472\n-0.044642\n0.039062\n0.001215\n0.016318\n0.015283\n-0.028674\n0.026560\n0.044529\n-0.025930\n220.0\n\n\n441\n-0.045472\n-0.044642\n-0.073030\n-0.081413\n0.083740\n0.027809\n0.173816\n-0.039493\n-0.004222\n0.003064\n57.0\n\n\n\n\n442 rows × 11 columns",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "k-nearest-neighbors.html",
    "href": "k-nearest-neighbors.html",
    "title": "5  K-Nearest Neighbors",
    "section": "",
    "text": "5.1 KNN for Classification\nLoad data.\nfrom sklearn.datasets import load_breast_cancer\n\ncancer = load_breast_cancer()\ncancer['data']\n\narray([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n        1.189e-01],\n       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n        8.902e-02],\n       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n        8.758e-02],\n       ...,\n       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n        7.820e-02],\n       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n        1.240e-01],\n       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n        7.039e-02]])\nSplit data.\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(cancer['data'], cancer['target'], random_state=42)\nX_train.shape, y_train.shape\n\n((426, 30), (426,))\nX_test.shape, y_test.shape\n\n((143, 30), (143,))\nTrain model.\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier()\nknn.predict(X_test)\n\narray([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1])\nknn.predict_proba(X_test).shape\n\n(143, 2)\nScore model.\nknn.score(X_test, y_test)\n\n0.965034965034965\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\ncancer = load_breast_cancer()\n\nX_train, X_test, y_train, y_test = train_test_split(cancer['data'], cancer['target'], random_state=42)\n\ntrain_scores, test_scores = [], []\n\nneighbor_candidates = range(1, 16)\nfor n_neighbors in neighbor_candidates:\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(X_train, y_train)\n    train_score = knn.score(X_train, y_train)\n    test_score = knn.score(X_test, y_test)\n\n    train_scores.append(train_score)\n    test_scores.append(test_score)\n    \n\nfig, ax = plt.subplots(1, 1, figsize=(8, 3))\nax.plot(neighbor_candidates, train_scores, 'b-h', label='train accuracy')\nax.plot(neighbor_candidates, test_scores, 'r-*', label='test accuracy')\nax.set_xlabel('Number of neighbors')\nax.set_ylabel('Accuracy')\nax.set_ylim([0.9, 1.02])\nax.legend()\nfig.tight_layout()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>K-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "k-nearest-neighbors.html#knn-for-regression",
    "href": "k-nearest-neighbors.html#knn-for-regression",
    "title": "5  K-Nearest Neighbors",
    "section": "5.2 KNN for Regression",
    "text": "5.2 KNN for Regression\n\nfrom sklearn.datasets import load_diabetes\n\ndiabetes = load_diabetes()\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(diabetes['data'], diabetes['target'], random_state=42)\n\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n((331, 10), (111, 10), (331,), (111,))\n\n\n\nfrom sklearn.neighbors import KNeighborsRegressor\n\nknn = KNeighborsRegressor(n_neighbors=3)\nknn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)\n\n\nknn.score(X_test, y_test)\n\n0.37222167132521977\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\n\ndiabetes = load_diabetes()\n\nX_train, X_test, y_train, y_test = train_test_split(diabetes['data'], diabetes['target'], random_state=42)\n\ntrain_scores, test_scores = [], []\nneighbor_candidates = range(1, 51)\nfor n_neighbors in neighbor_candidates:\n    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n    knn.fit(X_train, y_train)\n\n    train_score = knn.score(X_train, y_train)\n    test_score = knn.score(X_test, y_test)\n    train_scores.append(train_score)\n    test_scores.append(test_score)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 3))\nax.plot(neighbor_candidates, train_scores, 'b-h', label='train R squared')\nax.plot(neighbor_candidates, test_scores, 'r-*', label='test R squared')\nax.set_xlabel('Number of neighbors')\nax.set_ylabel('R squared')\nax.legend()\nfig.tight_layout()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>K-Nearest Neighbors</span>"
    ]
  }
]